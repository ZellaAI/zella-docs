---
title: "OpenAI SDK"
description: "Use OpenAI SDK to integrate with Zella"
---

### Chat Completion

Connect to the Zella AI Chat Completion API using OpenAI SDK.

<CodeGroup>

```python chat.py
from openai import OpenAI

client = OpenAI(
    api_key="*********", # Zella API Key
    base_url="https://gateway.zella.ai/v1/openai"
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "How do I add fallbacks in Zella?",
        }
    ],
    model="zella-101-test",
    # Platform is optional, only required if you are using a
    # model which is not not listed in Zella dashboard.
    extra_body={"platform": "zella"},
    stream=False,
)
print(chat_completion)
```

</CodeGroup>

### Chat Completion with streaming

To enable streaming responses, simply set the 'stream' attribute to True in the response object.
This feature is available only if the underlying model platform supports streaming. Below is a
sample implementation:

<CodeGroup>

```python chat_stream.py
from openai import OpenAI

client = OpenAI(
    api_key="*********", # Zella API Key
    base_url="https://gateway.zella.ai/v1/openai"
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "How do I add fallbacks in Zella?",
        }
    ],
    model="gpt-4",
    user="test-123",
    stream=True,
)
for chunk in chat_completion:
    print(chunk)
```

</CodeGroup>

### Chat Completion with Zella Prompt

You can pass Zella prompt identifier using OpenAI SDK too and utilise Zella's prompt management feature.

<CodeGroup>

```python chat_stream.py
from openai import OpenAI

client = OpenAI(
    api_key="*********", # Zella API Key
    base_url="https://gateway.zella.ai/v1/openai"
)

chat_completion = client.chat.completions.create(
    messages=[],
    model="gpt-4",
    extra_body={
        "prompt": {
            "prompt_id": "mathsprompt",
            "context": {
                "query": "What is 3+4?"
            }
        }
    },
    stream=True
)
for chunk in chat_completion:
    print(chunk)
```

</CodeGroup>

### Embeddings

Transform text into insightful vectors with Zella,
utilizing a range of embedding models and platforms for diverse applications.

<CodeGroup>

```python embedding.py
from openai import OpenAI

client = OpenAI(
    api_key="*********", # Zella API Key
    base_url="https://gateway.zella.ai/v1/openai"
)

embed_zella = client_zella.embeddings.create(
    input=["This is a test", "another test"],
    model="embedding-001",
    user="test-user",
)
print(embed_zella)
```
</CodeGroup>