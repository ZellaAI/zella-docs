---
title: 'Jobs'
description: 'Welcome to the Jobs feature in Zella AI! Jobs allow you to run AI models against 
datasets with specified prompts and configurations. This documentation will guide you through 
creating, running, and analyzing the results of jobs within the Zella AI platform.'
icon: 'circle-8'
---

## Introduction

In the world of AI development, testing and evaluating models against real-world data is crucial
for ensuring their effectiveness and reliability. Zella AI's Jobs feature facilitates this process
by providing a streamlined interface for running models against datasets and analyzing their performance.

## Running Jobs

Running a job in Zella AI is a streamlined process, designed to offer flexibility and ease of use.
Below are the steps involved in executing a job:

1. Selection of Model: Users initiate the job creation process by selecting a model from the available
   options in the Zella AI dashboard. The chosen model will be utilized to process the provided dataset.
2. Prompt Configuration: Users define the system prompt and user prompt to be used in the job. These prompts
   serve as the input for the AI model during the execution of the job. Users can populate prompt values using
   their Zella configured prompts. Additionally, to access input given in the dataset in the prompt, users can
   use a variable like this: {`{{INPUT}}`}.
3. Dataset Selection: Users specify the dataset against which the job will run. This dataset serves as
   the input for the AI model and prompts, allowing for comprehensive analysis and evaluation.
4. Evaluator Configuration: Users have the option to select Zella configured evaluators to evaluate
   the responses generated by the AI model for each item in the dataset. This step enables users to assess
   the performance and accuracy of the AI model against the provided prompts and dataset.

### Running the Job

Once you've configured the job settings, initiate the job by clicking the "Execute" button. Zella AI will
then execute the selected model against the dataset using the specified prompts and configurations.

## Result Analysis

Upon completion of the job, users can access detailed metrics and insights through the result page.
The result page provides a comprehensive overview of the job output and evaluation metrics. Below are
the key metrics displayed on the result page:

1. Pass Rate: Indicates the percentage of responses that passed the specified evaluation criteria.
2. Average Similarity Score: Represents the average similarity score between the generated responses
   and the expected outputs.
3. Total Tokens: Displays the total number of tokens processed during the job execution.
4. Total Latency: Reflects the total processing time taken for the job execution.
5. Total Evaluations Passed: Indicates the total number of evaluations that passed the specified criteria.
6. Total Evaluations Failed: Indicates the total number of evaluations that failed to meet the
   specified criteria.

Additionally, the result page provides detailed insights for each message processed during the job execution.
Users can review the original output, job output, and a detailed panel for each message, facilitating thorough
analysis and troubleshooting.

## Conclusion

With the comprehensive documentation provided for Jobs in Zella AI, developers can efficiently
leverage this feature to execute AI models against datasets, analyze results, and gain valuable
insights into model performance. The structured approach outlined in this documentation ensures
users can effectively utilize Jobs within the Zella AI platform for diverse use cases and applications.
