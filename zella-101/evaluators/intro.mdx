---
title: "Intro"
description: "Evaluators in Zella AI serve as indispensable tools for assessing and refining the performance, quality, and compliance of AI-powered systems. These evaluators come in various types, each tailored to address specific needs and objectives.
"
---

## What are Evaluators?
Evaluators in Zella AI are specialized mechanisms designed to rigorously assess different aspects of AI applications. They enable developers to systematically evaluate the effectiveness, accuracy, and appropriateness of AI models and interactions.

Evaluators encompass a wide range of functionalities, from assessing code logic to moderating content for compliance. By leveraging evaluators, developers can ensure that their AI systems meet the desired standards of performance, quality, and ethical standards.

## How Evaluators Work?
In Zella AI, evaluators empower developers by providing structured frameworks for evaluation and feedback. They facilitate various evaluation methods, such as code-based evaluation, language model assessment, content quality analysis, and content moderation checks.

By utilizing evaluators, developers can gain insights into the strengths and weaknesses of their AI applications. This allows for iterative improvement and optimization, leading to enhanced user experience and overall effectiveness.

## Types of Evaluators
Zella AI offers several types of evaluators to cater to different evaluation needs:

1. **Code Evaluator**: Evaluates based on code logic and implementation.
2. **LLM Evaluator**: Utilizes language models for assessment.
3. **Content Quality Evaluator**: Assesses input and output quality based on predefined metrics.
4. **Content Moderation Evaluator**: Ensures compliance with content guidelines and standards.
Each type of evaluator serves a unique purpose in evaluating AI systems, providing developers with comprehensive tools for evaluation and refinement.

## Utilizing Evaluators
Utilizing evaluators in Zella AI is a straightforward process aimed at empowering developers to make informed decisions and optimizations. Developers can configure evaluators according to their specific requirements, set thresholds for evaluation criteria, and monitor results in real-time.

By incorporating evaluators into their development workflow, developers can ensure the robustness, quality, and compliance of their AI applications, ultimately driving innovation and excellence in AI development.

