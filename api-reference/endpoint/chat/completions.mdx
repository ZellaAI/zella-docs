---
title: "Chat Completions"
api: "POST /v1/chat/completions"
---

# Chat Completion Request

## Request Headers

<ParamField body="Authorization" type="string" required="true">
  Zella Access key generated on dashboard. [See how to generate access key](/zella-101/setup-access#get-your-access-key).
</ParamField>


## Request Body Parameters

<ParamField body="user" type="string">
  The unique identifier of the user.
</ParamField>

<ParamField body="model" type="Object" required="true">
  The model configuration used for the chat completion. [See how to choose model configuration](/models).
    <Expandable title="properties">
        <ParamField path="platform" type="string">
            The AI platform used for the model. This is an optional field, only required when using models which
            are not listed in Zella dashboard.
        </ParamField>

        <ParamField path="name" type="string" required="true">
            The name of the AI model. This should be a valid model available on the specified platform.
        </ParamField>
        <ParamField path="timeout" type="number" required="false">
            The timeout for the model in milliseconds. Default is 60000. Must be an integer greater than -1 and less than 10 minutes (600000).
        </ParamField>
    </Expandable>

</ParamField>

<ParamField body="query" type="Object" required="true">
  Contains the query to be processed by the model.
    <Expandable title="properties">
        <ParamField path="messages" type="array" required="true">
            An array of message objects to be processed by the model. Each message object should have the following properties:
            <Expandable title="properties">
                <ParamField path="role" type="string" required="true">
                    The role of the message sender. This can be `user`, `system`, `assistant`, or `tool`.
                </ParamField>

                <ParamField path="content" type="string" required="true">
                    The content of the message.
                </ParamField>
                <ParamField path="name" type="string" required="false">
                    The name of the message sender.
                </ParamField>
                <ParamField path="tool_calls" type="array">
                    An array of tool call objects, applicable only if the role is `tool`.
                    <Expandable title="properties">
                        <ParamField path="id" type="string" required="true">
                            The unique identifier of the tool call.
                        </ParamField>
                        <ParamField path="type" type="string" required="true">
                            The type of the tool call. This can be `function` or other types.
                        </ParamField>
                        <ParamField path="function" type="Object" required="true">
                            The details of the function call.
                            <Expandable title="properties">
                                <ParamField path="name" type="string" required="true">
                                    The name of the function to be called.
                                </ParamField>
                                <ParamField path="arguments" type="string" required="true">
                                    The arguments to be passed to the function.
                                </ParamField>
                            </Expandable>
                        </ParamField>
                    </Expandable>
                </ParamField>
            </Expandable>
        </ParamField>
        <ParamField path="options" type="Object">
            Contains any additional parameters to be used by the model.
            <Expandable title="properties">
                <ParamField path="frequency_penalty" type="number">
                    The frequency penalty to be used by the model. Must be a number between -2 and 2. Default is 0.
                </ParamField>
                <ParamField path="logit_bias" type="Object">
                    The logit bias to be used by the model. Must be an object with keys as tokens and values as numbers. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
                    <Expandable title="properties">
                        <ParamField path="<token>" type="number" required="true">
                            Token must be a positive integer. The associated bias value from -100 to 100.
                        </ParamField>
                    </Expandable>
                </ParamField>
                <ParamField path="max_tokens" type="number">
                    The maximum number of tokens to be generated by the model. Must be an integer greater than 0.
                </ParamField>
                <ParamField path="variations" type="number">
                    The number of variations to be generated by the model. Must be an integer greater than 0 and less than 50. Default is 1.
                </ParamField>
                <ParamField path="presence_penalty" type="number">
                    The presence penalty to be used by the model. Must be a number between -2 and 2. Default is 0.
                </ParamField>
                <ParamField path="seed" type="number">
                    The seed to be used by the model. Must be an integer or null.
                </ParamField>
                <ParamField path="stop" type="array">
                    An array of strings to be used as stop sequences by the model. Must be an array of strings with a maximum of 4 strings or null.
                </ParamField>
                <ParamField path="temperature" type="number">
                    The temperature to be used by the model. Must be a number between 0 and 2. Default is 1.
                </ParamField>
                <ParamField path="top_k" type="number">
                    The number of highest probability vocabulary tokens to keep for nucleus sampling. Must be a number between 0 and 1 or null. Default is 1.
                </ParamField>
                <ParamField path="top_p" type="number">
                    The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be a number between 0 and 1 or null. Default is 1.
                </ParamField>
            </Expandable>
        </ParamField>
    </Expandable>

</ParamField>

<ParamField body="response" type="Object" required="true">
  Defines the desired response format and options.
  <Expandable title="properties">
    <ParamField path="format" type="string" required="true">
      The format of the response. Must be one of `text` or `json_object`.
      Default is `text`.
    </ParamField>
    <ParamField path="stream" type="boolean">
      Whether the response should be streamed. Default is `false`.
    </ParamField>
    <ParamField path="tools" type="array">
      An array of tools to be used for processing the response.
      <Expandable title="properties">
        <ParamField path="type" type="string" required="true">
          The type of the tool. Must be one of 'function'.
        </ParamField>
        <ParamField path="function" type="Object">
          The function to be used for processing the response.
          <Expandable title="properties">
            <ParamField
              path="name"
              type="string"
              required="true"
              max="64"
              regex="^[a-zA-Z0-9_-]+$"
            >
              The name of the function. Must be a string with a maximum length
              of 64 and match the regex /^[a-zA-Z0-9_-]+$/.
            </ParamField>
            <ParamField path="description" type="string">
              The description of the function.
            </ParamField>
            <ParamField path="parameters" type="Object">
              The parameters of the function.
              <ParamField path="<parameter>" type="any">
                The parameter name and type.
              </ParamField>
            </ParamField>
          </Expandable>
        </ParamField>
      </Expandable>
    </ParamField>
    <ParamField path="preferred_tool" type="string">
      The preferred tool to be used for processing the response. Must be one of
      the tools in the tools list.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="options" type="Object">
  Contains any additional parameters to be used by Gateway API.
</ParamField>

## Chat Completion Response

This response will contain the model's response to the chat completion request.

<ResponseField name="tryId" type="string">
  The unique identifier of the chat completion request.
</ResponseField>

<ResponseField name="status" type="Object">
  The status of the chat completion response.
  <Expandable title="properties">
    <ResponseField name="type" type="string">
      The type of the status. Can be one of `ok`, `platform_error`, `error`.
    </ResponseField>
    <ResponseField name="code" type="number">
        - `200` - The request was successful.
        - `400` - The request was invalid.
        - `401` - The request was unauthorized.
        - `611` - The request was forbidden.
        - `201` - The request was not found.
        - `600` - The request failed due to an internal server error.
        - `603` - The request failed due to a service unavailable error.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="model" type="Object">
  The model used for the chat completion response.
  <Expandable title="properties">
    <ResponseField name="platform" type="string">
      The platform of the model.
    </ResponseField>
    <ResponseField name="name" type="string">
      The name of the model.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="data" type="Object">
  The data of the chat completion response.
</ResponseField>

<ResponseField name="usage" type="Object">
  The usage of the chat completion response.
</ResponseField>

<ResponseField name="meta" type="Object">
  The meta information of the chat completion response.
</ResponseField>

<ResponseField name="retries" type="array">
  An array of retry objects.
  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The unique identifier of the retry.
    </ResponseField>
    <ResponseField name="platform" type="string">
      The platform of the retry.
    </ResponseField>
    <ResponseField name="name" type="string">
      The name of the retry.
    </ResponseField>
    <ResponseField name="error" type="string">
      The error message of the retry.
    </ResponseField>
    <ResponseField name="timeout" type="number">
      The timeout of the retry.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
```bash Curl

curl --request POST \
--url https://gateway.zella.ai/v1/chat/completions \
--header 'content-type: application/json' \
--header 'Authorization: Bearer api_h8j3g7cc68a89sc2eod' \
--data '{
"user": "user_jskjf93o101",
"model": {
    "platform": "openai",
    "name": "gpt-3.5-turbo"
},
"query": {
    "messages": [
        {
        "role": "system",
        "content": "You are a helpful assistant to help design api structure"
        },
        {
        "role": "user",
        "content": "Hi There!"
        }
    ]
},
"response": {
    "format": "json_object",
    "stream": true
    }
}'

````

```python Python

# Create Request Parameters
user = "user_jskjf93o101"
model = {
    "platform": "openai",
    "name": "gpt-3.5-turbo"
}
query = {
    "messages": [ {
        "role": "system",
        "content": "You are a helpful assistant to help design api structure"
    },
    {
        "role": "user",
        "content": "Hi There!"
    }]
}
response = {
    "format": "json_object",
    "stream": True
}

# Call API
stream = zella_ai.chat.completions.create(user, model, query, response)

# Iterate over stream
for chunk in stream:
    if chunk:
        print(chunk)
````

</RequestExample>

The example shows how to make a POST request to the Chat Completions API using curl and Python. The API requires a json body with the properties `user`, `model`, `query`, and `response`.

If the request is successful, the API will return a json object containing the model's response to the chat completion request. If there is an error, the API will return a json object containing details about the error.
